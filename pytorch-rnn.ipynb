{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580b55dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Shubham\\Downloads\\100_Unique_QA_Dataset (1).csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b75aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d86051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'the', 'capital', 'of', 'france']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"What is the capital of FraNCE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538de425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab\n",
    "vocab = {'<UNK>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4489bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "    tokenized_question = tokenize(row['question'])\n",
    "    tokenized_answer = tokenize(row['answer'])    \n",
    "    \n",
    "    merged_tokens = tokenized_question + tokenized_answer\n",
    "    \n",
    "    for token in merged_tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c52976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5e57d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a501c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab):\n",
    "    indexed_text = []\n",
    "    \n",
    "    for token in tokenize(text):\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "            \n",
    "        else:\n",
    "            indexed_text.append(vocab['<UNK>'])\n",
    "            \n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12166a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(\"What is campusx\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be474656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0cdc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        numerical_question = text_to_indices(self.df.iloc[idx]['question'],self.vocab)\n",
    "        numerical_answer = text_to_indices(self.df.iloc[idx]['answer'],self.vocab)        \n",
    "        return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cb434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a7ec0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94215b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([102])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([191])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([311])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([132])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([240])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\n",
      "tensor([[10, 96,  3, 97]]) tensor([98])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\n",
      "tensor([[10, 75, 76]]) tensor([77])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\n",
      "tensor([[ 10,  75, 111]]) tensor([112])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([160])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([32])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\n",
      "tensor([[ 10,  75, 208]]) tensor([209])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\n"
     ]
    }
   ],
   "source": [
    "for question, answer in dataloader:\n",
    "    print(question, answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f36ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb0294c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "        \n",
    "    def forward(self, question):\n",
    "        embedded_question = self.embedding(question)\n",
    "        hidden, final = self.rnn(embedded_question)\n",
    "        output = self.fc(final.squeeze(0))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4541441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a: torch.Size([1, 6])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "shape of b: torch.Size([1, 6, 50])\n",
      "shape of c: torch.Size([1, 6, 64])\n",
      "shape of d: torch.Size([1, 1, 64])\n",
      "tensor([[[-0.8057, -0.5245,  0.5298, -0.2934,  0.6493,  0.4695, -0.5646,\n",
      "          -0.7875,  0.0994,  0.6195, -0.6238, -0.2444, -0.4075,  0.0876,\n",
      "           0.7800, -0.0189,  0.0228,  0.3839, -0.5533,  0.5400,  0.0664,\n",
      "           0.2689, -0.2004,  0.2209,  0.3738,  0.2443, -0.1477, -0.4467,\n",
      "          -0.0965,  0.8675, -0.0134, -0.7055, -0.4149,  0.0583,  0.2238,\n",
      "           0.0751, -0.7544, -0.8150,  0.0750, -0.4997,  0.7260,  0.8579,\n",
      "          -0.0591, -0.9727, -0.2486,  0.2356, -0.3411,  0.6518,  0.7264,\n",
      "          -0.3310, -0.5263, -0.4822, -0.1302, -0.5407, -0.2336, -0.3029,\n",
      "           0.6174,  0.8679, -0.3832,  0.7346,  0.0817,  0.1723,  0.6434,\n",
      "           0.2013]]], grad_fn=<StackBackward0>)\n",
      "shape of e: torch.Size([1, 324])\n",
      "tensor([[ 0.1210, -0.1566,  0.6815,  0.5042,  0.3324, -0.2641, -0.0181,  0.1975,\n",
      "          0.2588,  0.2197,  0.0569,  0.0510,  0.0287,  0.2534,  0.3586,  0.1476,\n",
      "         -0.1129, -0.1108, -0.4872,  0.3016, -0.0506, -0.4057, -0.0518, -0.5270,\n",
      "         -0.0941,  0.6111,  0.1788, -0.3222,  0.3090,  0.1953,  0.3385, -0.6976,\n",
      "          0.2747,  0.0042,  0.3010, -0.0941, -0.4293, -0.7096,  0.0092,  0.4010,\n",
      "          0.0029, -0.1421,  0.1833, -0.3610, -0.2720,  0.1405, -0.0026,  0.0933,\n",
      "         -0.3018, -0.0400,  0.0555,  0.4024, -0.1252, -0.5337,  0.1676,  0.4281,\n",
      "         -0.1523, -0.4581,  0.1114,  0.2739,  0.0811, -0.5569, -0.3585, -0.2562,\n",
      "         -0.0131,  0.4534, -0.1837,  0.1970,  0.0180, -0.1187,  0.3966,  0.0774,\n",
      "         -0.1066, -0.1228,  0.3825,  0.0273, -0.4573, -0.4193,  0.3372,  0.3452,\n",
      "         -0.1361, -0.4293, -0.3109,  0.0523,  0.5918, -0.1159, -0.3234, -0.3560,\n",
      "         -0.3336, -0.1220,  0.0510,  0.0158,  0.2172,  0.0489, -0.2971, -0.0848,\n",
      "         -0.2424, -0.1377, -0.1069,  0.6099, -0.6760, -0.0941,  0.1674, -0.1230,\n",
      "         -0.3654,  0.2709, -0.0773,  0.1078,  0.4649, -0.0385,  0.0255,  0.3438,\n",
      "         -0.0588,  0.2381, -0.1214, -0.1230,  0.4454, -0.0551,  0.2459, -0.2386,\n",
      "          0.4784, -0.2081,  0.3543, -0.3742, -0.4129, -0.3837, -0.2109, -0.1465,\n",
      "         -0.0049,  0.3125,  0.1271,  0.1208,  0.1866, -0.3724,  0.1289,  0.2412,\n",
      "          0.2783,  0.0678,  0.3474, -0.0778,  0.2675,  0.5241, -0.0193, -0.5562,\n",
      "         -0.0014,  0.3446, -0.1173, -0.1916,  0.3647, -0.1448, -0.7806,  0.1656,\n",
      "          0.1731,  0.0484,  0.0910, -0.4012,  0.0815,  0.0072,  0.2086,  0.0345,\n",
      "         -0.5030,  0.3747,  0.1394, -0.2988, -0.1547,  0.2993, -0.1209,  0.2826,\n",
      "          0.3889, -0.0363, -0.2410, -0.3789, -0.6435, -0.0973, -0.1326, -0.0542,\n",
      "          0.1191, -0.0473,  0.6329, -0.0054,  0.4003,  0.2677,  0.1101,  0.1372,\n",
      "         -0.0497, -0.1588,  0.0209,  0.0037, -0.2956,  0.1265, -0.3469,  0.3362,\n",
      "          0.7293, -0.1997,  0.2505, -0.0406, -0.0818, -0.0273,  0.5740,  0.4852,\n",
      "         -0.0554,  0.1974,  0.3043,  0.3921, -0.1411, -0.6280, -0.0559, -0.6911,\n",
      "          0.0782,  0.2235, -0.0703, -0.0791,  0.5070, -0.3689, -0.2826, -0.2281,\n",
      "         -0.0860,  0.6043, -0.0682,  0.2958,  0.3441,  0.6083, -0.3222,  0.0100,\n",
      "          0.3381,  0.2988, -0.1827, -0.0510,  0.0784,  0.1226,  0.1577,  0.4802,\n",
      "          0.0060,  0.1457, -0.2452,  0.0760, -0.3176, -0.2493, -0.2598, -0.0055,\n",
      "         -0.3465, -0.3987, -0.0665, -0.0463, -0.0302,  0.1689, -0.2741,  0.6124,\n",
      "          0.1779, -0.2349,  0.1527, -0.3026, -0.3427,  0.1532, -0.3762,  0.1489,\n",
      "         -0.2409, -0.0081,  0.2494, -0.0855,  0.3683, -0.1534, -0.2013, -0.3883,\n",
      "         -0.1577, -0.5770, -0.1265,  0.2437,  0.0935,  0.0280, -0.3801, -0.1525,\n",
      "          0.1879,  0.4697, -0.3171, -0.3253,  0.0222,  0.3060,  0.1837, -0.1151,\n",
      "         -0.0194,  0.2280, -0.0486,  0.5437,  0.0659, -0.4219,  0.2851, -0.5096,\n",
      "          0.1104,  0.4168,  0.2875, -0.0344, -0.3632,  0.8424,  0.2175, -0.2876,\n",
      "         -0.2274,  0.2700, -0.0886,  0.1622,  0.2314,  0.1699, -0.2989, -0.6865,\n",
      "          0.1168,  0.3418, -0.0390, -0.0194,  0.0322,  0.0941, -0.1370,  0.0141,\n",
      "          0.1142, -0.3007,  0.2589, -0.2469, -0.0145,  0.0348,  0.1107, -0.8861,\n",
      "         -0.0509, -0.2850, -0.0191,  0.2832]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = nn.Embedding(324, embedding_dim=50)\n",
    "y = nn.RNN(50, 64, batch_first=True)\n",
    "z = nn.Linear(64, 324)\n",
    "\n",
    "a = dataset[0][0].reshape(1,6)\n",
    "print(\"shape of a:\", a.shape)\n",
    "print(a)\n",
    "b = x(a)\n",
    "print(\"shape of b:\", b.shape)\n",
    "c, d = y(b)\n",
    "print(\"shape of c:\", c.shape)\n",
    "print(\"shape of d:\", d.shape)\n",
    "print(d)\n",
    "e = z(d.squeeze(0))\n",
    "\n",
    "print(\"shape of e:\", e.shape)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "114c4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0903bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "873b7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad5668c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 524.439637\n",
      "Epoch: 2, Loss: 455.359987\n",
      "Epoch: 3, Loss: 378.357342\n",
      "Epoch: 4, Loss: 319.636662\n",
      "Epoch: 5, Loss: 270.368961\n",
      "Epoch: 6, Loss: 222.623930\n",
      "Epoch: 7, Loss: 180.041058\n",
      "Epoch: 8, Loss: 141.316396\n",
      "Epoch: 9, Loss: 109.551311\n",
      "Epoch: 10, Loss: 84.687659\n",
      "Epoch: 11, Loss: 65.410129\n",
      "Epoch: 12, Loss: 50.772824\n",
      "Epoch: 13, Loss: 40.611099\n",
      "Epoch: 14, Loss: 32.802083\n",
      "Epoch: 15, Loss: 27.066793\n",
      "Epoch: 16, Loss: 22.705714\n",
      "Epoch: 17, Loss: 18.928597\n",
      "Epoch: 18, Loss: 16.359158\n",
      "Epoch: 19, Loss: 14.005093\n",
      "Epoch: 20, Loss: 12.015365\n",
      "Epoch: 21, Loss: 10.489192\n",
      "Epoch: 22, Loss: 9.170419\n",
      "Epoch: 23, Loss: 8.038473\n",
      "Epoch: 24, Loss: 7.106094\n",
      "Epoch: 25, Loss: 6.330435\n",
      "Epoch: 26, Loss: 5.681115\n",
      "Epoch: 27, Loss: 5.111967\n",
      "Epoch: 28, Loss: 4.629950\n",
      "Epoch: 29, Loss: 4.210727\n",
      "Epoch: 30, Loss: 3.842353\n",
      "Epoch: 31, Loss: 3.525603\n",
      "Epoch: 32, Loss: 3.231743\n",
      "Epoch: 33, Loss: 2.970435\n",
      "Epoch: 34, Loss: 2.747857\n",
      "Epoch: 35, Loss: 2.544521\n",
      "Epoch: 36, Loss: 2.354911\n",
      "Epoch: 37, Loss: 2.191987\n",
      "Epoch: 38, Loss: 2.040063\n",
      "Epoch: 39, Loss: 1.905600\n",
      "Epoch: 40, Loss: 1.776497\n",
      "Epoch: 41, Loss: 1.662883\n",
      "Epoch: 42, Loss: 1.554055\n",
      "Epoch: 43, Loss: 1.454167\n",
      "Epoch: 44, Loss: 1.367451\n",
      "Epoch: 45, Loss: 1.283666\n",
      "Epoch: 46, Loss: 1.208068\n",
      "Epoch: 47, Loss: 1.135098\n",
      "Epoch: 48, Loss: 1.069619\n",
      "Epoch: 49, Loss: 1.007121\n",
      "Epoch: 50, Loss: 0.951070\n",
      "Epoch: 51, Loss: 0.896434\n",
      "Epoch: 52, Loss: 0.849126\n",
      "Epoch: 53, Loss: 0.801479\n",
      "Epoch: 54, Loss: 0.756028\n",
      "Epoch: 55, Loss: 0.716461\n",
      "Epoch: 56, Loss: 0.678068\n",
      "Epoch: 57, Loss: 0.641584\n",
      "Epoch: 58, Loss: 0.608606\n",
      "Epoch: 59, Loss: 0.576310\n",
      "Epoch: 60, Loss: 0.546393\n",
      "Epoch: 61, Loss: 0.518003\n",
      "Epoch: 62, Loss: 0.490992\n",
      "Epoch: 63, Loss: 0.466795\n",
      "Epoch: 64, Loss: 0.443646\n",
      "Epoch: 65, Loss: 0.420727\n",
      "Epoch: 66, Loss: 0.400299\n",
      "Epoch: 67, Loss: 0.379727\n",
      "Epoch: 68, Loss: 0.361554\n",
      "Epoch: 69, Loss: 0.343307\n",
      "Epoch: 70, Loss: 0.326579\n",
      "Epoch: 71, Loss: 0.310839\n",
      "Epoch: 72, Loss: 0.295600\n",
      "Epoch: 73, Loss: 0.281405\n",
      "Epoch: 74, Loss: 0.268035\n",
      "Epoch: 75, Loss: 0.255295\n",
      "Epoch: 76, Loss: 0.242731\n",
      "Epoch: 77, Loss: 0.231303\n",
      "Epoch: 78, Loss: 0.220454\n",
      "Epoch: 79, Loss: 0.210069\n",
      "Epoch: 80, Loss: 0.200137\n",
      "Epoch: 81, Loss: 0.190557\n",
      "Epoch: 82, Loss: 0.181900\n",
      "Epoch: 83, Loss: 0.173335\n",
      "Epoch: 84, Loss: 0.165443\n",
      "Epoch: 85, Loss: 0.157566\n",
      "Epoch: 86, Loss: 0.150366\n",
      "Epoch: 87, Loss: 0.143309\n",
      "Epoch: 88, Loss: 0.136814\n",
      "Epoch: 89, Loss: 0.130429\n",
      "Epoch: 90, Loss: 0.124398\n",
      "Epoch: 91, Loss: 0.118786\n",
      "Epoch: 92, Loss: 0.113353\n",
      "Epoch: 93, Loss: 0.108066\n",
      "Epoch: 94, Loss: 0.103210\n",
      "Epoch: 95, Loss: 0.098446\n",
      "Epoch: 96, Loss: 0.094096\n",
      "Epoch: 97, Loss: 0.089781\n",
      "Epoch: 98, Loss: 0.085709\n",
      "Epoch: 99, Loss: 0.081805\n",
      "Epoch: 100, Loss: 0.078121\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for question, answer in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(question)\n",
    "        \n",
    "        loss = criterion(y_pred,answer[0])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a7613eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold = 0.5):\n",
    "    \n",
    "    numerical_question = text_to_indices(question, vocab)\n",
    "    reverse_dict = {v:k for k,v in vocab.items()}\n",
    "    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "    output = model(question_tensor)\n",
    "    \n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    value, index = torch.max(probs, dim=1)\n",
    "    \n",
    "    if value < threshold:\n",
    "        print(\"I don't know\")\n",
    "    else:\n",
    "        print(reverse_dict[index.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4889bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n"
     ]
    }
   ],
   "source": [
    "predict(model,\"What is the capital of country France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7076e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee94e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae9022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151fdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad266b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff008b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbc179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
